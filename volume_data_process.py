import matplotlib.pyplot as plt
import matplotlib
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.ensemble import RandomForestClassifier
import matplotlib.dates as mdates
from mplfinance.original_flavor import candlestick_ohlc

matplotlib.use('TkAgg')


class VolumeDataProcess:
    def __init__(self, file_path):
        self.file_path = file_path

    def to_min_of(self, minute):
        import pandas as pd

        df = pd.read_csv(self.file_path, parse_dates=['date'])
        df.set_index('date', inplace=True)

        # é‡é‡‡æ ·ä¸º3åˆ†é’Ÿæ•°æ®
        df_min = df.resample(f'{minute}T').agg({
            'open': 'first',
            'high': 'max',
            'low': 'min',
            'close': 'last',
            'volume': 'sum'
        }).dropna().reset_index()
        df_min.to_csv(f"LC_20230721_20251030_{minute}min.csv", index=False)
        return df_min

    def resample_to_volume(self, volume_threshold):
        """
        æ ¹æ®ç»™å®šæˆäº¤é‡é˜ˆå€¼ç”Ÿæˆç­‰é‡ Bar
        volume_threshold: æ¯æ ¹Barçš„ç›®æ ‡æˆäº¤é‡
        """
        # è¯»å–æ•°æ®
        df = pd.read_csv(self.file_path, parse_dates=['date'])

        # åˆå§‹åŒ–å˜é‡
        bars = []
        cum_vol = 0
        o, h, l, c = df['open'].iloc[0], df['high'].iloc[0], df['low'].iloc[0], df['close'].iloc[0]
        start_time = df['date'].iloc[0]

        for idx, row in df.iterrows():
            price_open, price_high, price_low, price_close, vol = \
                row['open'], row['high'], row['low'], row['close'], row['volume']

            # ç´¯ç§¯æˆäº¤é‡
            cum_vol += vol
            h = max(h, price_high)
            l = min(l, price_low)
            c = price_close

            # è¾¾åˆ°é˜ˆå€¼ç”ŸæˆBar
            if cum_vol >= volume_threshold:
                end_time = row['date']
                time_delta = (end_time - start_time).total_seconds()

                bars.append({
                    'open': o,
                    'high': h,
                    'low': l,
                    'close': c,
                    'volume': cum_vol,
                    'start_time': start_time,
                    'end_time': end_time,
                    'time_delta_sec': time_delta
                })

                # é‡ç½®ç´¯è®¡å˜é‡
                cum_vol = 0
                o, h, l, c = price_open, price_high, price_low, price_close
                start_time = row['date']

        # å¤„ç†æœ€åä¸€æ ¹æœªæ»¡é˜ˆå€¼çš„Bar
        if cum_vol > 0:
            end_time = df['date'].iloc[-1]
            time_delta = (end_time - start_time).total_seconds()

            bars.append({
                'open': o,
                'high': h,
                'low': l,
                'close': c,
                'volume': cum_vol,
                'start_time': start_time,
                'end_time': end_time,
                'time_delta_sec': time_delta
            })

        volume_bar_df = pd.DataFrame(bars)
        volume_bar_df.to_csv(f"LC_20230721_20251030_volumebar_{volume_threshold}.csv", index=False)

        return volume_bar_df

    def plot_volume_bars(self, volume_bar_df, title='Volume Bars'):
        """
        ç»˜åˆ¶ç­‰é‡ Bar çš„Kçº¿å›¾
        volume_bar_df: åŒ…å« ['open','high','low','close','volume','start_time'] çš„DataFrame
        """
        # å…ˆè½¬æ¢æ—¶é—´ä¸ºmatplotlibå¯è¯†åˆ«çš„æµ®ç‚¹æ•°
        ohlc = volume_bar_df.copy()
        ohlc['date_float'] = mdates.date2num(ohlc['start_time'])
        ohlc_data = ohlc[['date_float', 'open', 'high', 'low', 'close']].values

        # åˆ›å»ºå›¾è¡¨
        plt.figure(figsize=(12, 6))
        ax = plt.gca()

        # ç»˜åˆ¶Kçº¿
        candlestick_ohlc(ax, ohlc_data, width=0.0005, colorup='g', colordown='r')

        # è®¾ç½®Xè½´æ—¶é—´æ ¼å¼
        ax.xaxis_date()
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))

        plt.title(title)
        plt.xlabel('Time')
        plt.ylabel('Price')
        plt.grid(True)
        plt.tight_layout()
        plt.savefig('volume_bars.png')
        plt.show()

    def get_pct(self):
        df_volume = pd.read_csv("LC_20230721_20251030_volumebar_5800.csv")
        # å½“å‰è¡Œä¸ä¸‹ä¸€è¡Œçš„å˜åŒ–
        df_volume['pct_change_1'] = df_volume['close'].pct_change(periods=1).shift(-1)

        # å½“å‰è¡Œä¸åä¸¤è¡Œçš„å˜åŒ–
        df_volume['pct_change_2'] = (df_volume['close'].shift(-2) - df_volume['close']) / df_volume['close']
        df_volume['pct_change_5'] = (df_volume['close'].shift(-5) - df_volume['close']) / df_volume['close']
        return df_volume

    def plot_volume_over_time(self, minute):
        df = self.to_min_of(minute)
        self.plot_data_distribution(minute, df, 'volume')

    def plot_data_distribution(self, minute, df, label):
        # è®¡ç®—ä¸­ä½æ•°
        print(f"Plotting distribution for {minute}-Minute {label}")
        V_bar = df[label].quantile(0.5)
        print(f"Median volume (50% quantile) as threshold: {V_bar}")

        # è®¡ç®—å¹³å‡å€¼
        mean_value = df[label].mean()
        print(f"Mean volume: {mean_value}")

        plt.figure(figsize=(10, 5))
        plt.hist(
            df[label],
            bins=100,
            edgecolor='black',
            density=True  # <== yè½´å½’ä¸€åŒ–åˆ°æ¦‚ç‡å¯†åº¦
        )
        plt.title(f'{minute}-Minute {label} Distribution')
        plt.xlabel(f'{label}')
        plt.ylabel('Density (0-1)')
        # ç»˜åˆ¶ä¸­ä½æ•°çº¿
        plt.axvline(V_bar, color='red', linestyle='--', label=f'Median={V_bar:.2f}')
        plt.legend()
        # ç»˜åˆ¶å¹³å‡å€¼çº¿
        plt.axvline(mean_value, color='green', linestyle='--', label=f'Mean={mean_value:.2f}')
        plt.legend()
        # plt.show()
        plt.savefig(f'{minute}min_{label}_distribution.png')

    def plot_data(self):
        df = pd.read_csv(self.file_path, parse_dates=['date'])
        plt.figure(figsize=(12, 6))
        plt.plot(df['date'], df['volume'], label='3-Minute Volume')
        plt.xlabel('Date')
        plt.ylabel('Volume')
        plt.title('3-Minute Resampled Volume Data')
        plt.legend()
        plt.show()

    def get_threshold(self):
        pct = self.get_pct()
        label = pct['pct_change_1'].dropna()  # å»æ‰ NaN

        # å³ä¾§ç´¯ç§¯æ¦‚ç‡ 0.35 å¯¹åº”å·¦ä¾§ç´¯ç§¯æ¦‚ç‡ 0.65
        threshold = np.quantile(label, 0.6)

        print("å³ä¾§é¢ç§¯0.35å¯¹åº”çš„é˜ˆå€¼:", threshold)
        # 0.0002714
        return threshold

    def mark_label(self):
        df_volume = pd.read_csv("LC_20230721_20251030_volumebar_4780.csv")
        df_volume['pct_change_1'] = df_volume['close'].pct_change(periods=1).shift(-1)
        threshold = self.get_threshold()
        df_volume['label'] = (df_volume['pct_change_1'] > threshold).astype(int)
        return df_volume

    def train_model_RF(self):
        df_3min = self.mark_label()

        # ====== é€‰æ‹©ç‰¹å¾åˆ— ======
        # æ ¹æ®ä½ çš„æ•°æ®ç»“æ„è‡ªè¡Œä¿®æ”¹ï¼Œå¦‚æœä½ æ²¡æœ‰å…¶å®ƒç‰¹å¾ï¼Œå¯å…ˆç”¨ price ç±»ç‰¹å¾æµ‹è¯•
        feature_cols = [
            'open', 'high', 'low', 'close', 'time_delta_sec'
        ]
        feature_cols = [c for c in feature_cols if c in df_3min.columns]

        if not feature_cols:
            raise ValueError("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨ç‰¹å¾åˆ—ï¼Œè¯·æ£€æŸ¥ CSV ä¸­æ˜¯å¦åŒ…å« open/high/low/close/volume")

        X = df_3min[feature_cols]
        y = df_3min['label']

        n_samples = len(X)
        train_size = int(n_samples * 0.7)  # 70% è®­ç»ƒé›†ï¼Œ30% æµ‹è¯•é›†

        # æ‰‹åŠ¨åˆ’åˆ†
        X_train = X[:train_size]
        X_test = X[train_size:]
        y_train = y[:train_size]
        y_test = y[train_size:]

        # # ====== åˆ’åˆ†è®­ç»ƒ / æµ‹è¯• ======
        # X_train, X_test, y_train, y_test = train_test_split(
        #     X, y, test_size=0.3, shuffle=False  # é¢„æµ‹æ—¶é—´åºåˆ—ä¸æ‰“ä¹±
        # )

        # ====== éšæœºæ£®æ— ======
        model = RandomForestClassifier(
            n_estimators=300,
            max_depth=15,
            min_samples_split=10,
            random_state=42,
            n_jobs=-1,
            class_weight='balanced'  # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
        )

        # model = RandomForestClassifier(
        #     n_estimators=100,
        #     criterion='gini',
        #     random_state=42,
        #     class_weight='balanced'
        # )

        model.fit(X_train, y_train)

        ####
        y_train_pred = model.predict(X_train)
        print("ğŸ¯ RandomForest Train Accuracy:", accuracy_score(y_train, y_train_pred))
        print(classification_report(y_train, y_train_pred))
        # ====== é¢„æµ‹ ======
        y_pred = model.predict(X_test)

        # ====== è¾“å‡ºç»“æœ ======
        print("ğŸ¯ RandomForest Accuracy:", accuracy_score(y_test, y_pred))
        print("\nğŸ“‹ Classification Report:")
        print(classification_report(y_test, y_pred))
        df_con = pd.DataFrame({
            'Actual': y_test,
            'Predicted': y_pred
        })

        # ====== ç‰¹å¾é‡è¦æ€§ ======
        fi = pd.DataFrame({
            'feature': feature_cols,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        print("\nğŸ” Feature Importance:")
        print(fi)

        return model, fi


if __name__ == '__main__':
    data_process = VolumeDataProcess("LC_20230731_20251030.csv")
    df = data_process.to_min_of()
    print(df.head(5))
